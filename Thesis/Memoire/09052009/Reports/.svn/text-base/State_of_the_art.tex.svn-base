\chapter{Related Work}

% Try to say the "easy" or "obvious" things first (ex: define the problem)! Then describe the "standard" approach to QA and its variants.

% Define firstly the task: what exactly QA means, what are the question and answer that are expected?
A question answering system allows users ask a question in natural language and receive an exact and succinct answer in place of a list of documents that contain the answer \cite{kato2004hia, hirschman2002nlq}. Since the first article that addressed a textual question answering system by computer was presented by Simmons (1965)\cite{simmons1965aeq}, many systems have been developed and some of approaches have been widely used in many applications, for instance Okapi BM2. A typical question answering system is showed in the Figure \ref{fig: Question Answering Architecture}.

\begin{figure}[htbp]
\centering
\includegraphics[scale = 0.5]{QASystem.jpg}
\caption{A typical Question Answering Architecture}
\label{fig: Question Answering Architecture}
\end{figure}

In a general question answering system, there are four major components \cite{tellex2003pmf, hirschman2002nlq,tellex2003qep, bilotti2004wbq}:

\begin{itemize}
\item {Question analysis: There are two tasks in this component. Firstly, question in natural language asked by a user need to be converted into queries that are needed by the subsequent parts of the system. The queries created from user's question contain terms likely to appear in documents containning an answer, for instance for such question as \textit{What is the capital of Vietnam?}, the corresponding query is \textit{capital + vietnam}. Secondly, expected type of this question is detected in this stage so that it helps to narrow space of searched answer. For example, questions with "When" always relate to \textit{time}, thus those terms concerning time are remarked such as \textit{date}, \textit{hour}, etc. }.
\item {Document retrieval: This task is to retrieve documents from the corpus that may be taken from Internet by a search engine or archived documents likely to contain answers to the query.}
\item {Passage retrieval: A passage can simply be defined as a sequence of words regardless sentences or paragraphs. Some text-based information retrieval systems define a passage as a fixed-length block of words. \cite{goharian2008dsp}. Passage retrieval algorithms take a document and a question, and try to return a list of passages from the document most likely to contain an answer information. The most relevant passages have the highest score, namely passage score, that is generally calculated based on matched words between the document and the question.  }
\item {Answer extraction: Based on question analysis and retrieved passages, the system extracts phrase/phrases representing an answer.}
\end{itemize}

We are interested in only passage retrieval stage because in our case, questions and document are defined as the BET questions and meeting transcript as mentioned above. For this reason, we present only state-of-the-art methods related to passage retrieval including both traditional methods and modern methods.


Most passage retrieval algorithms calculate passage score based on words or phases from passage that are found in the question, namely matched words. However, the way to compute matched word score is different for each algorithm. The simplest algorithm for this approach proposed by Light\cite{light2002aec}, in which a passage score function counts the number of words from question found in the passage as the score for this passage. That means all words are treated at the same important level. Many questions answering systems use this method as a baseline score to evaluate their performance. Up to date, there are many passage retrieval methods presented in the Text Retrieval Conference (TREC) \url{http://trec.nist.gov}. However, these methods can be classified into two groups. One group including traditional methods assigns scores to each matched words independently. That means there are not any relations between two matched words. Another group including modern methods considers relations amongst matched words to assign scores to them. For traditional methods, typical approaches use parts-of-speech and frequencies of a word to give a score for it. Meanwhile for modern ones, dependency relation among matched words in a phrase is computed to give a score for this phrase instead of words. This makes it more semantic than with traditional methods.

Take SiteQ's passage retrieval algorithm \cite{lee2002seh} as an example, a passage consists of some consecutive sentences segmented by punctuation and passage score is calculated by summing the weights of individual sentence in the passages. Each sentence gets score by a formula that combines both parts-of-speech method and query term density method. In detail, the weight of the matched words is assigned as follows: A proper noun, a common noun recognized by a capital letter has higher score than a verb, an adjective and an adverb. The term density is defined as the distance among matched words. Then if two sentences have the same number of matched words the sentence with smaller distance will have higher score.

The main idea of using word frequencies is that if a word appears many times in a current passage but a few in other passages, its score in this current passage is higher \cite{robertson2004uid}. That means the importance of a word increases proportionally to the number of times this word found in a passage but inversely to the number of times this word found in the total document. The Okapi BM25 \cite{robertson1996ot, beaulieu1995ot, xue2008rmq, comas2008sdr, tellex2003qep} presents as state-of-the-art for assigning weights to matched words using word frequencies. In fact, Okapi BM25 is a ranking function that is used to rank matching documents according to their relevance to a given query. Thus, it is rather used in the Document Retrieval stage of the system. However, according to Okapi BM25 presented in the TREC-4 \cite{robertson1996ot}, this function is also used for passage determination and searching. In addition, it is a complex function which was developed from the function of term frequency-inverse document frequency \textit{tf-idf} \cite{robertson2004uid}. 

Modern approaches consider dependency relation among matched words and according to it, n-gram is the simplest case. The n-gram method pays more attention to the order of matching words. Accordingly, those in order is better. More specifically, this method is used to estimate similarity between two strings by examining all n-word substring matching instead of word matching \cite{robertson1998ang}. Another simple method is to use word density presented in the SiteQ's algorithm above. A more complex method for these approaches presented by Cui \cite{cui2005qap} that uses a dependency tree to assign scores to sentences. Given the reason that one sentence in English can be written in different ways by exchanging position of words in the sentence without chaning its meaning. For instance, with the sentence \textit{Jean wrote a science fiction book}, it may be written in 6 different ways but the meaning remains unchanged. They include: \textit{A science fiction book was written by Jean}, \textit{Jean wrote a book of science fiction}, \textit{A book of science fiction was written by Jean}, \textit{Jean wrote a book of fiction of science} and \textit{A fiction of science book was written by Jean}. These sentences can build a dependency tree that represents correctly position relations of the words in the sentences, so that a given question will be compared with this tree instead of one initial sentence.
 
In order to enhance the performance of question answering systems, lexical extensions for queries are added such as stemming, lemma, synonyms \cite{light2002aec}, \cite{tellex2003pmf},\cite{bilotti2004wbq}, \cite{lee2002seh}.
